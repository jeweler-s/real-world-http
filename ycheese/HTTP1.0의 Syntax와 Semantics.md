### 왜 HTTP가 지금의 모습이 됐는가?
>🔥 **HTTP란?** 웹 브라우저와 웹 서버가 통신하는 절차와 형식을 규정한 것

**HTTP 통신 내용의 4요소**

- Method와 Path
- Header
- Body
- Status Code

💡 curl 커맨드를 사용해서 원하는대로 서버에 요청도 해보자

### 🧢 header

HTTP의 헤더는 이메일과 똑같은 형식이다.
1)요청에만 사용되는 것, 2)응답에만 사용되는 것, 3)양 쪽 다 사용되는 것이 있다.

**Request Header**
- User-Agent: 클라이언트가 자신의 이름을 넣는 곳(브라우저 종류, 버전 구분 가능)
- Referer: 보고 있던 페이지의 URL
- Authorization: 인증 정보(Basic, Digest, Bearer)

**Response Header**

- Content-Type: 파일 종류
    - MIME 타입: 파일의 종류를 구별하는 문자열
        - MIME 무시, 내용을 보고 파일 형식을 추측하는 것은 `콘텐트 스니핑`, 보안 구멍이 될 수 있음
        - `X-Content-Type-Options: nosniff` 로 브라우저가 추측하지 않도록 지시할 수 있음
- Content-Length: 바디 크기(압축이 이루어졌다면 압축 후 크기)
- Content-Encoding: 압축이 이루어진 경우 압축 형식
- Date: 문서 날짜

`X-`로 시작되는 헤더는 자유롭게 사용 (사용자 정의 헤더)

### 👵🏻 http의 조상님들

**이메일**

- MIME 타입은 이메일이 원조
- 둘 다 헤더 + 본문 구조로 이루어짐
- HTTP 요청은 method + path 가 추가됨
- HTTP 응답은 status code가 추가됨

**뉴스 그룹**

- method, status code는 뉴스 그룹이 원조

### 🖥️ Status Code
>🤔 서버가 어떻게 응답했나요?
- **100번대**: 처리가 계속됨
- **200번대**: 성공
- **300번대**: 서버→클라이언트 명령
- **400번대**: 클라이언트 요청에 오류
- **500번대**: 서버 내부 오류

### 🗺️ URL
`스키마://호스트명/경로`의 구조
URL full 사양: `스키마://사용자:패스워드@호스트명:포트/경로#프래그먼트?쿼리`

- **스키마**: http, https, mailto, file, ftp, …
    - 스키마 해석은 브라우저의 책임! 브라우저가 스키마를 보고 적절한 접속 방법을 선택함
- **호스트명**: 실제로 통신하는 서버
- **프래그먼트**: 페이지 내 링크의 앵커 지정

**🐈 재밌는 요소들**
- URL에 단어가 포함되면 구글 검색 엔진에 플러스 된다?!
- URL 길이 제한은 없지만 IE는 2083자 까지만 다룰 수 있다?!
    - HTTP/2 시대가 되면서 URL이 지나치게 길면 `414 URI Too Long`이 반환된다.
    

### 🪄 curl 커맨드
```bash
curl —http1.0 —get —data-urlencode “search word” http://localhost:18888
```
```bash
curl —http1.0 -H “X-Test: Hello” http://localhost:18888
```
```bash
curl --http1.0 -X POST http://localhost:18888/greeting
```

**기타 …**
- **-v**: 서버에서 반환하는 헤더 표시
- **-d**: 서버에 바디 전송
- **-F**: `enctype=”multipart/form-data”` 설정된 폼 형식 바디 전송 (-d와 혼합 사용 불가)
- **@**: 파일 전송

### 🍪 쿠키
웹사이트 정보를 브라우저에 저장하는 HTTP 헤더 기반으로 구현된 작은 파일

**단점**
- `영속성`: 사라지더라도 문제 없는 정보만 저장
- `용량`: 최대 4KB
- `보안`: HTTP 통신에서 평문으로 전송됨
→ 쿠키 수명 설정, https일 때만 사용하게끔 제한 등등 제약을 둘 수 있다 ~

### 🩻 인증과 세션
**BASIC 인증**
- BASE64로 정보 인코딩
- SSL/TLS 통신을 사용하지 않으면 정보 유출 가능

**Digest** **인증**
- 해시 함수로 보다 강력해짐
- 방대한 계산 리소스 사용
  
**이것들 .. 왜 안 쓰이나 🤔**
- 요청할 때마다 id/pw 인증해야 함
- 명시적인 로그아웃 불가
- 단말 식별 불가
- …
→ 폼을 이용한 로그인 + 쿠키를 이용한 세션 관리를 최근에는 많이 사용한다 ~

🔎 (87p) **프록시와 게이트웨이의 차이 ?**

**프록시**
  - 통신 내용을 이해한다.
  - 필요에 따라서 컨텐츠를 수정 또는 서버 대신 응답한다.

**게이트웨이**
  - 통신 내용을 그대로 전송한다.

### 💰 캐시
>💡 안 바뀌었으면, 그냥 있는거 쓰자!

**Pragma: no-cache**
- 요청한 컨텐츠가 이미 있어도, origin에서 가져오라고 프록시에게 지시
- HTTP/1.1에 Cache-Control로 통합됨 (호환성 유지 위해 남아있음)

**Expires**
- 날짜와 시간으로 해당 기간 내라면 강제로 캐시를 이용함
- 서버에 변경 사항이 있는지 묻지 않게 되므로 주의

**ETag**
- 동적 요소가 늘어날수록 무엇으로 캐시의 유효성을 판단할지 어렵다! → **파일의 해시값으로 비교하자**

**Cache-Control**
- `Expires`보다 우선 처리
    - `Cache-Control: no-store` 는 캐시하지 않음

### 🗂️ Vary
같은 URL이라도 클라이언트에 따라 반환 결과가 다름을 나타내는 헤더

**예를 들면…**
- 스마트폰에서는 모바일용 페이지가 표시됨
- 로그인이 필요한 사이트에는 쿠키를 지시함
- 검색 엔진용 힌트로도 사용됨

### 👣 Referer
사용자가 어느 경로로 웹사이트에 도달했는지 서버가 파악할 수 있도록 클라이언트가 보내는 헤더
목적지가 https라면 출발지에 관계없이 리퍼러를 전송하지만, https→http(다운그레이드)의 경우 전송하지 않음

### 💼 크롤러 접근 제어

**robots.txt**

서버 콘텐츠 제공자가 크롤러에 접근 허가 여부를 전하기 위한 프로토콜

**사이트맵**

웹사이트에 포함된 페이지 목록과 메타데이터를 제공하는 XML 파일

→ `robots.txt`는 블랙리스트, `사이트맵`은 화이트리스트처럼 사용됨 !

→ 사이트맵은 robots.txt에 쓸 수도 있다
